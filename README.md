# Directory Roadmap

#### `data/`
Contains datasets and generated playscripts.
- `permanent/`:
  - `premises.csv`: ChatGPT generated premises. Two types of premises: `creative` and `neutral`. A `creative` example: "Two rivals in a political campaign debate their policies during a televised interview." We decided creative premises might be more likely to cause the model to generate text with a certain emotion, so we switched to `neutral`. A `neutral` example: "Two friends discuss their plans for the weekend."
  - `example_playscripts.csv`: ChatGPT generated playscripts to be used for muulti-shot prompting.
  - `generated_playscripts.csv`: Playscripts generated from `premises.csv`. Has both Llama-generated playscripts and GPT-4o-generated playscripts. GPT-4o-generated playscripts are specified with `alice_emotion` and `bob_emotion`.
  - `emotion_metrics.csv`: Emotion scores for `generated_playscripts.csv`. Hyperparameters include:
    - `probing_model`: llama2_13b_chat
    - `probing_method`: pca, logistic_regression
    - `stimulis_format`: simple (no prompting), rep e ("Consider the {sentiment} of the following scenario: "), conversation ("Consider the {sentiment} of the following conversation: ")
    - `dialogue_concatenate`: True (dialogues are gradually concatenated throughout the playscript and scored), False (dialogues are scored independently)

#### `representation-engineering/`
Contains code and resources for emotion classification.
- **Setup:**
  - Clone the repository: `git clone https://github.com/andyzoujm/representation-engineering.git`
  - Follow the installation instructions provided in the repository.
- **Important Subdirectories:**
  - `data/emotions/`: Used to train the emotion classifier.
  - `repe/rep_readers.py`: Contains RepReader class, which is used to identify concept directions. We implement the LogisticRegressionRepReader class, copy the code from `rep_e_edits.ipynb`.
  - `examples/primary_emotions/`: Contains example Jupyter notebooks.
    - `emotion_concept.ipynb`: Reference code for writing `measure_emotions.ipynb`.
    - `utils.py`: Edit `primary_emotions_concept_dataset()` to split the train and test data in 50/50 ratio. By default, they are the same (weird). Copy the code from `rep_e_edits.ipynb`.

#### `scripts/`
Scripts for generating playscripts and analyzing emotion metrics.
- **Notebooks:**
  1. `generate_playscripts.ipynb`: Generates playscripts from `premises.csv`. Playscripts can be generated by specifying Alice and Bob's emotion, or generic completion. Generated playscripts are stored in `generated_playscripts.csv`.
  2. `measure_emotions.ipynb`: Measures emotions in the generated playscripts. Emotion scores are stored in `emotion_metrics.csv`.
  3. `playscript_emotion_analytics.ipynb`: Analyzes the emotion metrics of the generated playscripts.